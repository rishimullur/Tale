<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aphasia Speech Assistance</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f8f9fa;
            margin: 0;
            padding: 0;
        }

        h1 {
            text-align: center;
            color: #333;
            margin-top: 20px;
        }

        .container {
            display: flex;
            justify-content: space-around;
            align-items: flex-start;
            /* Aligns children at the start of the cross axis */
            margin: 20px auto;
            max-width: 800px;
            background-color: #fff;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            padding: 20px;
        }

        .box {
            width: 45%;
            min-height: 300px;
            /* Use min-height to ensure boxes can expand as needed */
            border: 1px solid #ddd;
            border-radius: 10px;
            padding: 20px;
            background-color: #f5f5f5;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            transition: all 0.3s ease;
        }

        .box:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
        }

        .mic-icon {
            font-size: 64px;
            margin-bottom: 20px;
            color: #007bff;
        }

        #record-button {
            padding: 10px 20px;
            font-size: 18px;
            border: none;
            border-radius: 5px;
            background-color: #007bff;
            color: #fff;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }

        #record-button:hover {
            background-color: #0056b3;
        }

        .recording {
            background-color: #dc3545 !important;
        }

        .output-box {
            background-color: #e9ecef;
            color: #495057;
            border: 1px solid #ced4da;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
            min-height: 300px;
            /* Use min-height to ensure boxes can expand as needed */
            border-radius: 10px;
            padding: 20px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            transition: all 0.3s ease;
        }

        .output-box p {
            margin-top: 5px;
            font-size: 16px;
            color: #212529;
        }

        .output-box p:first-child {
            font-weight: bold;
            font-size: 18px;
        }

        .output-box p:last-child {
            font-style: italic;
        }
    </style>
</head>

<body>
    <h1>Aphasia Speech Assistance</h1>

    <div class="container">
        <div class="box" id="record-box">
            <span class="mic-icon">üéôÔ∏è</span>
            <button id="record-button" type="button" onclick="toggleRecording()">Start Listening</button>
        </div>

        <div class="box output-box">
            <p id="transcribed-text">You said: </p>
            <p id="suggestion-text">AI suggestion: </p>
        </div>
    </div>

    <script>
        let isRecording = false;
        let mediaRecorder;
        let audioChunks = [];

        function startRecording() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    console.log("Recording started.");
                    mediaRecorder = new MediaRecorder(stream);
                    audioChunks = []; // Reset the chunks array for a new recording session

                    // Start recording. Adjust the time slice to change how often chunks are sent
                    mediaRecorder.start(10000); // e.g., 10000ms = 10s chunks

                    mediaRecorder.addEventListener("dataavailable", event => {
                        if (event.data.size > 0) {
                            console.log("Uploading an audio chunk.");
                            uploadAudio(event.data); // Send each chunk right away
                        }
                    });

                    mediaRecorder.addEventListener("stop", () => {
                        // Handle what happens once recording is stopped if needed
                        // Only create and send the blob if there's enough data
                        if (audioChunks.length > 0 && audioChunks[0].size > 1000) { // The size check here is arbitrary, adjust based on typical chunk sizes you see
                            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                            uploadAudio(audioBlob);
                        } else {
                            console.error("Not enough audio data to send a file.");
                        }
                        audioChunks = [];
                    });
                })
                .catch(console.error);
        }

        function uploadAudio(audioBlob) {
            // Check if the audioBlob has enough data
            if (audioBlob.size <= 1000) { // You can adjust the size check as needed
                console.error("Not enough audio data to send a file.");
                return; // Exit the function if blob size is too small
            }

            const formData = new FormData();
            formData.append("audio-file", audioBlob, "chunk.wav"); // Use a generic name as it's a chunk

            fetch("/record", { method: "POST", body: formData }) // Make sure this endpoint is set up in Flask to handle chunked uploads
                .then(response => response.json())
                .then(data => {
                    // Check if the response contains an error due to insufficient data
                    if (data.error && data.error.includes("No audio file provided")) {
                        console.error("No enough data to process."); // Log error to console and do not update the UI
                    }
                    else {
                        // Update the UI with transcription and suggestion
                        document.getElementById('transcribed-text').textContent = "You said: " + (data.transcription || "");
                        document.getElementById('suggestion-text').textContent = "AI suggestion: " + (data.suggestion || "");
                    }
                })
                .catch(error => console.error("Error uploading audio chunk:", error));
        }

        function stopRecording() {
            console.log("Recording stopped.");
            mediaRecorder.stop();
        }

        function toggleRecording() {
            const button = document.getElementById('record-button');
            if (isRecording) {
                stopRecording();
                button.textContent = "Start Listening";
            } else {
                startRecording();
                button.textContent = "Stop Listening";
            }
            isRecording = !isRecording;
            button.classList.toggle('recording');
        }
    </script>
</body>

</html>
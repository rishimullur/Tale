<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aphasia Speech Assistance</title>
    <link rel= "stylesheet" type= "text/css" href= "{{ url_for('static',filename='styling/main.css') }}">
</head>

<body>
    <div class="title">
        <h1>Tale: Aphasia Speech Assistant</h1>
    </div>

    <div class="centered-container">
        <div class="container">
            <div class="box" id="record-box">
                <span class="mic-icon">üéôÔ∏è</span>
                <button id="record-button" type="button" onclick="toggleRecording()">Start Listening</button>
            </div>

            <div class="box output-box">
                <p id="transcribed-text">You Said: </p>
                <p id="suggestion-text">Suggested Word: </p>
            </div>
        </div>
    </div>

    <script>
        let isRecording = false;
        let mediaRecorder;
        let audioChunks = [];

        function startRecording() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    console.log("Recording started.");
                    mediaRecorder = new MediaRecorder(stream);
                    audioChunks = [];

                    mediaRecorder.ondataavailable = event => {
                        if (event.data.size > 0) {
                            audioChunks.push(event.data);
                        }
                    };
                    mediaRecorder.start(1000);
                })
                .catch(error => console.error("Error accessing audio stream:", error));
        }

        function stopRecording() {
            mediaRecorder.stop(); // This will trigger the onstop event
            mediaRecorder.onstop = () => {
                sendAudioToBackend();
                audioChunks = []; // reset for the next recording
            };
        }

        function sendAudioToBackend() {
            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
            const formData = new FormData();
            formData.append("audio-file", audioBlob);

            fetch("/record", { method: "POST", body: formData })
                .then(response => response.json())
                .then(data => {
                    if (data.error) {
                        console.error("Error:", data.error);
                    } else {
                        document.getElementById('transcribed-text').textContent = "You said: " + data.transcription;
                        if (data.suggestion) {
                            document.getElementById('suggestion-text').textContent = "AI suggestion: " + data.suggestion;
                        }
                    }
                })
                .catch(error => console.error("Error uploading audio chunk:", error));
        }

        function toggleRecording() {
            const button = document.getElementById('record-button');
            const micIcon = document.querySelector('.mic-icon'); // Get the mic icon element

            if (isRecording) {
                stopRecording();
                button.textContent = "Start Listening";
                micIcon.classList.remove('listening'); // Stop the pulsating effect
            } else {
                startRecording();
                button.textContent = "Stop Listening";
                micIcon.classList.add('listening'); // Start the pulsating effect
            }
            isRecording = !isRecording;
            button.classList.toggle('recording');
        }
    </script>
</body>

</html>